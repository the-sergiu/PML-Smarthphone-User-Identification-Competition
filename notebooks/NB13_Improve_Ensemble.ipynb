{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d7eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergiu\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import lazypredict\n",
    "import xgboost as xgb\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, StackingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "# import optuna\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c53605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add, Input, Dense, Dropout, BatchNormalization, Embedding, Flatten, Concatenate, Reshape, Conv1D, AveragePooling1D, Multiply, MaxPool1D, Activation\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow_addons.layers import WeightNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422658f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ce850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39709545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(preds):\n",
    "    assert len(preds) == 5000\n",
    "    \n",
    "    # Read labels\n",
    "    with open('test_labels_sorted.npy', 'rb') as f:\n",
    "        test_labels = np.load(f)\n",
    "    len(test_labels)\n",
    "    \n",
    "    submission = pd.DataFrame(columns=['id', 'class'])\n",
    "    for label, pred in zip(test_labels, preds):\n",
    "        submission = submission.append({'id': label, 'class': pred}, ignore_index=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63047aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_val_from_train: np.array, y_pred_from_train: np.array):\n",
    "    \"\"\"Plot confusion matrix given predictions and truth values\"\"\"\n",
    "    _, ax = plt.subplots(figsize=(8, 5))\n",
    "    cmp = ConfusionMatrixDisplay(confusion_matrix(y_val_from_train, y_pred_from_train))\n",
    "    cmp.plot(ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe52386",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd0c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.66868409,  0.16353656,  0.63277468, ..., -0.68600237,\n",
       "        -0.75071056, -0.6719989 ],\n",
       "       [ 0.37202545,  0.27579237,  0.65904756, ...,  0.06479231,\n",
       "        -0.48439794,  0.56611352],\n",
       "       [-1.67047552, -1.2187742 , -2.37040642, ..., -0.65838631,\n",
       "        -0.38095167, -0.1542973 ],\n",
       "       ...,\n",
       "       [-0.24270722, -0.14209669, -0.32285351, ...,  0.37591901,\n",
       "        -0.37936549,  0.58761686],\n",
       "       [ 0.38630325,  0.31266521,  0.37767149, ...,  0.83458681,\n",
       "         0.3138927 ,  0.79569199],\n",
       "       [ 0.33077964, -0.0822815 , -0.51143673, ..., -1.1650511 ,\n",
       "        -0.410986  ,  0.44873132]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load X_train\n",
    "with open('X_train_64_std.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3e97ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7, 13,  6, ...,  3,  3, 18], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load y_train\n",
    "with open('y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "print(y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1247ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.59806336,  0.6264903 , -0.15256881, ...,  1.17376188,\n",
       "         0.23880484,  0.48877589],\n",
       "       [-0.47352949,  0.94441404, -0.23499654, ..., -0.41222519,\n",
       "        -0.40989637, -0.65814035],\n",
       "       [-0.64168924, -1.56209892, -1.06875674, ...,  0.3385773 ,\n",
       "        -0.56342902,  0.74796695],\n",
       "       ...,\n",
       "       [ 1.00103725, -0.3371114 ,  0.37115316, ..., -1.16055904,\n",
       "        -0.46010399, -0.62722221],\n",
       "       [-0.98752639, -1.20156778, -1.41423994, ..., -0.81406819,\n",
       "        -0.78249592,  1.12406601],\n",
       "       [-0.21177287, -0.85742305, -0.54931118, ...,  0.02750228,\n",
       "        -0.76809252, -1.25225668]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load X_train\n",
    "with open('X_test_64_std.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "print(X_test.shape)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9e1ed",
   "metadata": {},
   "source": [
    "## Create Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0027e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergiu\\.conda\\envs\\tf\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "etc_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=933, max_depth=79, min_samples_split=2, min_samples_leaf=1, \\\n",
    "                               bootstrap = False, warm_start = False)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_leaf=0.1, \\\n",
    "                                    min_samples_split=0.1363, subsample=1.0)\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(objective='multiclass', num_class=20, n_jobs=-1, seed=42, boosting='dart', \\\n",
    "                             min_child_samples=12, num_iterations=1936, num_leaves=66, min_data_in_leaf=50, \\\n",
    "                             max_bin=20, max_depth=17, learning_rate=0.24, reg_alpha=0.0004127769671094072)\n",
    "\n",
    "cbc_clf = CatBoostClassifier()\n",
    "\n",
    "tabnet = TabNetClassifier(optimizer_params=dict(lr=2e-2), scheduler_params={\"step_size\":10, \"gamma\":0.9}, scheduler_fn=torch.optim.lr_scheduler.StepLR)\n",
    "tabnet._estimator_type = \"classifier\"\n",
    "\n",
    "estimators = [(\"etc\", etc_clf), (\"gb\", gb_clf), (\"lgb\", lgb_clf), (\"cbc\", cbc_clf), ('tabnet', tabnet)]\n",
    "ensemble_estimators = StackingClassifier(estimators, final_estimator=LogisticRegression(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7400070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('etc',\n",
       "                                ExtraTreesClassifier(max_depth=79,\n",
       "                                                     n_estimators=933,\n",
       "                                                     n_jobs=-1)),\n",
       "                               ('gb',\n",
       "                                GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                                           max_depth=5,\n",
       "                                                           min_samples_leaf=0.1,\n",
       "                                                           min_samples_split=0.1363)),\n",
       "                               ('lgb',\n",
       "                                LGBMClassifier(boosting='dart',\n",
       "                                               learning_rate=0.24, max_bin=20,\n",
       "                                               max_depth=17,\n",
       "                                               min_child_samples=12,\n",
       "                                               min_data_in_leaf=50,\n",
       "                                               num_class=20,\n",
       "                                               num_iterations=1936,\n",
       "                                               num_leaves=66,\n",
       "                                               objective='multiclass',\n",
       "                                               reg_alpha=0.0004127769671094072,\n",
       "                                               seed=42)),\n",
       "                               ('cbc',\n",
       "                                <catboost.core.CatBoostClassifier object at 0x0000026828F043D0>),\n",
       "                               ('tabnet',\n",
       "                                TabNetClassifier(cat_dims=[], cat_idxs=[], optimizer_params={'lr': 0.02}, scheduler_params={}))],\n",
       "                   final_estimator=LogisticRegression(), n_jobs=-1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ensemble_estimators.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97391517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">etc 0.956 (0.006)\n",
      ">gb 0.957 (0.005)\n",
      ">lgb 0.961 (0.005)\n",
      ">cbc 0.961 (0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergiu\\.conda\\envs\\tf\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">tabnet 0.935 (0.006)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_list = []\n",
    "estimator_list = []\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for estimator_name, clf in estimators:\n",
    "    results = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    estimator_list.append(estimator_name)\n",
    "    results_list.append(results)\n",
    "    \n",
    "    print('>%s %.3f (%.3f)' % (estimator_name, np.mean(results), np.std(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23b917",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77930d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, ..., 4, 5, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ensemble_estimators.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db5313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10009</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>23986</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>23991</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>23992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>23998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id class\n",
       "0     10001     3\n",
       "1     10002     4\n",
       "2     10004     5\n",
       "3     10008    20\n",
       "4     10009    13\n",
       "...     ...   ...\n",
       "4995  23986     9\n",
       "4996  23991    12\n",
       "4997  23992     4\n",
       "4998  23998     5\n",
       "4999  24000     1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = make_submission(preds)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0650343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission_new_ensemble_baseline_64f_std_5_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e831b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
